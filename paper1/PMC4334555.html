<p>369 elite breeding lines were selected for genotyping from the International Rice Research Institute (IRRI) irrigated rice breeding program based on the planned inclusion of the lines in the 2011 Multi-Environment Testing Program and presence in the 2011 and 2012 Replicated Yield Trials (RYT) at IRRI (Los Ba&#241;os). Approximately half of the lines were also included in the 2009&#8211;2010 RYTs at IRRI (<xref ref-type="supplementary-material" rid="pgen.1004982.s006">S1 Table</xref>). The other lines were promoted from the observational yield trial (OYT) to the RYT in 2011.</p><p>Phenotypes for the replicated yield trials (RYT) were used for all the experiments and curated from the IRRI database for years 2009&#8211;2012, including wet and dry seasons each year. All of the RYT breeding lines, of which our selected 369 lines are a subset, were grown in a randomized complete block design with three replicates in the same field location at IRRI every season and year. The following data were curated for each year, with the exception that plant height data was not available for the 2009 wet season:
<list list-type="bullet"><list-item><p>plant height: the actual measurement in cm from soil surface to tip of tallest panicle (awns excluded)</p></list-item><list-item><p>flowering time: days to when 50% of flowers were visible in whole plot</p></list-item><list-item><p>maturity date: days to when 85% of grains on panicle were mature</p></list-item><list-item><p>number of effective tiller or panicle per plant: count of the number of panicles on each plant</p></list-item><list-item><p>lodging score: percent of plants that lodged</p></list-item><list-item><p>grain yield (kg/ha): grain yield from a representative plot was harvested and weighed, from this sample the grain yield per hectare was calculated from an inner harvested area of the plot excluding border rows</p></list-item><list-item><p>rep: replication number of observation</p></list-item></list>
</p><p>plant height: the actual measurement in cm from soil surface to tip of tallest panicle (awns excluded)</p><p>flowering time: days to when 50% of flowers were visible in whole plot</p><p>maturity date: days to when 85% of grains on panicle were mature</p><p>number of effective tiller or panicle per plant: count of the number of panicles on each plant</p><p>lodging score: percent of plants that lodged</p><p>grain yield (kg/ha): grain yield from a representative plot was harvested and weighed, from this sample the grain yield per hectare was calculated from an inner harvested area of the plot excluding border rows</p><p>rep: replication number of observation</p><p>The plant height, flowering time, and grain yield phenotypes were selected for prediction using the genomic selection models.</p><p xmlns:ns0="http://www.w3.org/1999/xlink">
<bold>DNA extraction</bold>. Young leaf tissue was collected from each of the 369 breeding lines from plants grown in Gutterman Greenhouse in Ithaca, NY. DNA was extracted using the Qiagen 96-plex DNeasy kit as per the Qiagen fresh leaf tissue 96-plex protocol (<ext-link ext-link-type="uri" ns0:href="http://www.qiagen.com/HB/DNeasy96Plant">www.qiagen.com/HB/DNeasy96Plant</ext-link>).</p><p>
<bold>Library preparation</bold>. 384-plex genotyping-by-sequencing (GBS) libraries were prepared using the protocol by Elshire <italic>et al</italic>. 2011 [<xref ref-type="bibr" rid="pgen.1004982.ref062">62</xref>], as described previously in Spindel and Wright <italic>et al</italic> 2013 [<xref ref-type="bibr" rid="pgen.1004982.ref063">63</xref>].</p><p>
<bold>GBS data analysis</bold>. SNPs were discovered and called from the raw 384-plex GBS data using the TASSEL3.0 GBS pipeline with physical alignment to the MSU version 6.0 Nipponbare rice reference genome using Bowtie2, as described in Spindel and Wright <italic>et al</italic> 2013 [<xref ref-type="bibr" rid="pgen.1004982.ref047">47</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref063">63</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref064">64</xref>] (<xref ref-type="supplementary-material" rid="pgen.1004982.s005">S5 Fig.</xref>). The IRRI breeding materials genotyped here are a collection of multi-parent related and unrelated inbred lines, so the GBS-PLAID algorithm for imputation, which was developed specifically for imputation of biparental rice mapping populations, was not useful [<xref ref-type="bibr" rid="pgen.1004982.ref063">63</xref>]. Imputation of missing data was instead performed using the TASSEL3.0 FastImputationBitFixedWindow plugin with default settings [<xref ref-type="bibr" rid="pgen.1004982.ref048">48</xref>]. The algorithm works by dividing the entire SNP dataset into small SNP windows, then identifying the most similar inbred line within each window to fill the missing data. The algorithm takes advantage of small IBD regions shared between pairs of inbred lines in the collection; if the window from the closest neighbor has more than 5% difference from the line being imputed, the data point is left as missing [<xref ref-type="bibr" rid="pgen.1004982.ref048">48</xref>]. The imputation error rate using this algorithm was estimated for each chromosome in our dataset by masking a fraction of the un-imputed allele calls and comparing the imputed and actual calls. The average imputation error rate across the twelve rice chromosomes was estimated in this way to be less than 1%.</p><p>SNPs that still had 10% or more data missing after imputation (or call rates of &lt; 90%) were removed from the dataset along with all monomorphic SNPs, for a total SNP set of 73,147 SNPs. After the SNP filtering described above, individuals with more than 60% missing data were dropped from the dataset, which resulted in the removal of six individuals that failed sequencing for the total of 363 genotyped lines used throughout the study (<xref ref-type="supplementary-material" rid="pgen.1004982.s005">S5 Fig.</xref>).</p><p>The final dataset was then transformed from nucleotide genotype coding (i.e., 'A', 'C', 'T', 'G') to numeric coding (1, 0, -1 for class I homozygotes, heterozygotes, and class II homozygotes, respectively) to facilitate statistical analysis. The minimal remaining missing data were filled using the numeric genotype means of each line in order to perform PCA and genomic selection modeling (<xref ref-type="supplementary-material" rid="pgen.1004982.s005">S5 Fig.</xref>).</p><p>The majority of the 363 lines were characterized <italic>a priori</italic> from pedigree records to belong to the <italic>indica</italic> or <italic>indica-admixed</italic> subpopulation groups. In order to identify outlier individuals belonging to the <italic>japonica</italic> or <italic>japonica-admixed</italic> groups, principle components analysis (PCA) was performed in R (version 3.0.1) using the imputed 73,147 SNPs, with remaining missing data filled using the line means. The first principal component of high density SNP data in rice can separate the <italic>indica</italic> and <italic>japonica</italic> subgroups [<xref ref-type="bibr" rid="pgen.1004982.ref030">30</xref>], so by plotting the first four principal components using JMP Pro 10, 13 <italic>japonica</italic> outliers were identified as a tight cluster that was pulled apart from the rest of the 350 lines (<xref ref-type="supplementary-material" rid="pgen.1004982.s001">S1A Fig.</xref>). These 13 lines were removed from the dataset, and a second PCA was performed using the same methodology as the first to identify any admixed outliers, i.e, outlier lines containing greater percentages of <italic>japonica</italic> derived SNPs. By plotting the first four principal components of the second PCA, another 18 lines were judged on a visual basis to be outliers and removed from the dataset, leaving a total of 332 lines to be used for the cross-validation experiments (<xref ref-type="supplementary-material" rid="pgen.1004982.s001">S1B Fig.</xref>). A third PCA was performed using the remaining 332 to confirm that there were no additional subpopulation outliers.</p><p>It was also known from studying the breeding program pedigrees that differing degrees of family relatedness existed within the remaining 332 lines, including half sibs, full sibs, parents and offspring, and unrelated lines. The presence of highly related individuals in the dataset could have the effect of artificially inflating prediction accuracy if the most closely related individuals are randomly assigned to different folds, and one of those folds is then used as training, while the other is used as testing. Or, in other words, the training fold could end up as unusually predictive of the testing fold if, for example, a pair of full sibs is split across training and testing folds. To control for this possibility when designing our folds, we performed a partitioning around k-medoids analysis (pamk) using the R fpc package (function pamk) with the 73,147 SNPs. k values from 2 to 332 were tested to determine the most statistically probable k-value by average silhouette width (<xref ref-type="supplementary-material" rid="pgen.1004982.s002">S2 Fig.</xref>). The largest average silhouette width was found to occur at k = 87 (<xref ref-type="supplementary-material" rid="pgen.1004982.s002">S2A Fig.</xref>). Individuals found within same cluster of 87 were then assigned to the same fold, making it impossible for the most closely related individuals to be split across training and testing folds. Full clusters were assigned to one of five folds randomly, controlling only for cluster size in order to produce three folds of 66 individuals and two folds of 67 individuals. A similar procedure was used by Ly et al., 2013 [<xref ref-type="bibr" rid="pgen.1004982.ref026">26</xref>].</p><p>For each cross validation experiment, one of the five folds served as the validation fold, and the other four folds served as the training folds. The process was repeated five times so that each fold served once as the validation fold, resulting in predicted GEBV values for all individuals. Accuracy was assessed as the mean Pearson Correlation of the predicted GEBV and observed phenotype in the validation population.</p><p>The cross validation experiments shown in <xref ref-type="table" rid="pgen.1004982.t003">Table 3</xref> were performed in order to test all logical combinations of years and seasons in the training and validation populations. Note that a year's wet season was never used to predict the same year's dry season because in Southeast Asia, the dry season arrives first chronologically. We did, however, predict the 2012 wet season both with and without the 2012 dry season present in the training population. We tested scenarios in which both seasons per year were included in the training population as well as scenarios where only the data from the seasons matching the validation population were included in the training data (e.g., using only the wet season data to predict the wet season). We also sought to test scenarios using only more recent year data in the training population (e.g. only 2011, or 2010&#8211;2011) and scenarios using more historical year data in the training population (e.g. 2009&#8211;2011) (<xref ref-type="table" rid="pgen.1004982.t003">Table 3</xref>).</p><p>*AS = all seasons, DS = dry season only, WS = wet season only</p><p>Cross validation experiment 1 (CV1) accuracies were calculated for all experiments with the validation year/season included in the training population, excluding individuals in the validation fold. Including the validation year/season in the training population can bias accuracies upwards by confounding GxE and line effects, however, so in order to obtain an estimate of this bias, we also performed cross validation experiments 2 and 3 (CV2, CV3) for CV permutations 1&#8211;5, see above table. For CV2, we excluded the validation year/season from the training population. These results are not directly comparable to those in which the training population contained the validation year/season (CV1), however, because the training population for CV2 is smaller than was used for CV1 and training population size can have an important effect on prediction accuracy. For this reason, we performed CV3, in which we included the validation year/season in the training population, but removed the equivalent seasons from 2011, e.g., for the first cross-validation permutation in the above table, CV2 would not include the 2012 dry season in the training population, and CV3 <italic>would</italic> include the 2012 dry season but would <italic>not</italic> include the 2011 dry season. Thus, the estimate of bias can be calculated for a given CV permutation experiment as CV3 accuracy minus the CV2 accuracy [<xref ref-type="bibr" rid="pgen.1004982.ref026">26</xref>]. The bias was only estimated for the first five CV permutations because the bias estimates turned out to be small and similar to each other for all five CV permutations.</p><p>For all three traits, multiple years, seasons, and replicate yield entries existed along with the previously described covariates for all 332 individuals. In order to build genomic selection models, it was necessary to convert these raw yields into a single, adjusted yield for each individual. Adjusted yields, plant heights, or days to flowering were calculated for each year/season combination by fitting an initial linear model of the observations <italic>y</italic>, by line ID (GHID) <italic>x</italic>
<sub><italic>1</italic>,</sub> and phenotype covariates described above (e.g. lodging) <italic>x</italic>
<sub><italic>2</italic>&#8230;<italic>n</italic></sub> for the given Year x Season in JMP. Non-significant covariates as determined by an F-test (&#945; &gt; = 0.05) or covariates that resulted in singularities were removed, and the model re-fit. When all covariates included in the model were statistically significant, the least squares mean yield for each line ID was exported as the adjusted yield. Missing phenotype data were coded as null data for the above analysis, or, in other words, no imputation or numeric filling of phenotypic values was performed.</p><p>The least square means for each year and season were also used to calculate a correlation matrix for each trait (<xref ref-type="supplementary-material" rid="pgen.1004982.s003">S3 Fig.</xref>).</p><p>For each experiment, adjusted yields were calculated for each of the five training folds separately by fitting a linear model for each training fold as described above with the difference that data from all years and seasons for a particular CV experiment was including in the x matrices for all lines not in the validation fold. Year, season, and a year x season interaction were also included as covariates in the model, and subject to the same significance requirements as the other model covariates.</p><p>Six statistical methods were used for each experiment, including four genomic selection methods: RR-BLUP, Bayesian LASSO (BL), Reproducing Kernel Hilbert Spaces (RKHS), and Random Forest (RF), and two non-genomic selection methods: Multiple Linear Regression (MLR) and Pedigree-BLUP (PED). The four genomic selection methods were chosen based on their demonstrated success in accurately predicting GEBV in variety of crops and because they represent the different types of statistical methodologies used to build GS models, i.e., Linear parametric methods (RR-BLUP, BL), non-linear semi-parametric methods (RKHS), non-linear, non-parametric methods (RF), as well as Frequentist methods (RR-BLUP, RKHS), Bayesian methods (BL), and machine learning methods (RF) [<xref ref-type="bibr" rid="pgen.1004982.ref019">19</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref023">23</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref049">49</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref050">50</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref065">65</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref066">66</xref>,<xref ref-type="bibr" rid="pgen.1004982.ref067">67</xref>]. For an overview of the methods, see Lorenz <italic>et al</italic>., 2011[<xref ref-type="bibr" rid="pgen.1004982.ref008">8</xref>].</p><p>Multiple linear regression using a subset of markers derived from single marker regressions (MLR), another linear, parametric statistical method was the fifth statistical method tested to predict breeding value, and served as our used as a non-GS marker-based prediction control. For each fold, single marker regression was run for all markers and p-values determined for each marker by f-test. Note that this is the statistical equivalent of a crude GWAS. Linear models were then tested using 1 through the first 100 most significant markers, and the model with the best fit was returned. The returned model was then used to calculate the accuracy for the given fold. For the marker subset experiments where the number of markers (p) was less than 100, models were tested using 1 through p markers. MLR has been shown to be effective for agronomic traits with very simple genetic architectures, but is otherwise not expected to perform well [<xref ref-type="bibr" rid="pgen.1004982.ref051">51</xref>].</p><p>Prediction based on pedigree alone was the sixth statistical method and was performed in order to determine if a.) the fold design method properly controlled for family structure within the dataset, and b.) if GS could outperform prediction based on pedigree alone [<xref ref-type="bibr" rid="pgen.1004982.ref052">52</xref>].</p><p>All statistical modeling was done in R. For the pedigree models an A-matrix was calculated using a three-generation pedigree file for all individuals in the training and validation populations using a custom R function. The models themselves were calculated using package rrBLUP (function kin.BLUP). RR-BLUP models were also calculated using package rrBLUP (function kinship.BLUP). RKHS models were calculated using kinship.BLUP, K.method = "GAUSS", modified so that parameter theta was always equal to 2.5, as per guidelines in the BGLR package documentation [<xref ref-type="bibr" rid="pgen.1004982.ref068">68</xref>]. Random Forest was performed using package randomForest (function randomForest). Bayesian LASSO was performed using package BLR (function BLR).</p><p>Narrow sense heritabilities were calculated for each trait on a per line basis using the rrBLUP package, function mixed.solve, with the least square means for the complete validation populations used as input. The narrow sense heritabilities were calculated as the additive genetic variance divided by the total phenotypic variance. The set of 73,147 SNPs was used for all experiments with the exception of the marker subset experiments described below.</p><p>The cross-validation results were analyzed using ANOVA and pairwise student's t to determine:
<list list-type="simple"><list-item><label>a</label><p>significant difference in the accuracy of prediction of the two validation populations across statistical methods, i.e., where <italic>y</italic>
<sub><italic>i</italic></sub> (accuracy) = <italic>&#956;</italic> + <italic>x</italic>
<sub><italic>ij</italic></sub>
<italic>&#946;</italic>
<sub><italic>j</italic></sub> + <italic>&#949;</italic>
<sub><italic>ij</italic></sub>, and <italic>i</italic> is one RYT experiment and stat method for validation population <italic>j</italic> (e.g. <italic>x</italic>
<sub><italic>i</italic></sub>
<italic>=</italic> CV experiment 1 for method RR-BLUP and <italic>j</italic> = validation population 2012 DS).</p></list-item><list-item><label>b</label><p>significant difference in the performance of the six statistical methods across the different experiments, i.e., where <italic>y</italic>
<sub><italic>i</italic></sub> (accuracy) = <italic>&#956;</italic> + <italic>x</italic>
<sub><italic>ij</italic></sub>
<italic>&#946;</italic>
<sub><italic>j</italic></sub> + <italic>&#949;</italic>
<sub><italic>ij</italic></sub>, and <italic>i</italic> is one RYT experiment for stat method <italic>j</italic> (e.g. <italic>x</italic>
<sub><italic>i</italic></sub> = CV experiment 1 and <italic>j</italic> = RR-BLUP).</p></list-item><list-item><label>c</label><p>significant difference in the performance of each experiment across statistical methods, after excluding the three worst-performing statistical methods (Bayesian LASSO, MLR, and pedigree only), i.e., where <italic>y</italic>
<sub><italic>i</italic></sub> (accuracy) = <italic>&#956;</italic> + <italic>x</italic>
<sub><italic>ij</italic></sub>
<italic>&#946;</italic>
<sub><italic>j</italic></sub> + <italic>&#949;</italic>
<sub><italic>ij</italic>,</sub> and <italic>i</italic> is one statistical method for RYT experiment <italic>j</italic> (e.g. <italic>x</italic>
<sub><italic>i</italic></sub> = RR-BLUP and j = CV experiment 1) (<xref ref-type="table" rid="pgen.1004982.t001">Table 1</xref>, <xref ref-type="supplementary-material" rid="pgen.1004982.s007">S2</xref>&#8211;<xref ref-type="supplementary-material" rid="pgen.1004982.s009">S4</xref> Tables).</p></list-item></list>
</p><p>significant difference in the accuracy of prediction of the two validation populations across statistical methods, i.e., where <italic>y</italic>
<sub><italic>i</italic></sub> (accuracy) = <italic>&#956;</italic> + <italic>x</italic>
<sub><italic>ij</italic></sub>
<italic>&#946;</italic>
<sub><italic>j</italic></sub> + <italic>&#949;</italic>
<sub><italic>ij</italic></sub>, and <italic>i</italic> is one RYT experiment and stat method for validation population <italic>j</italic> (e.g. <italic>x</italic>
<sub><italic>i</italic></sub>
<italic>=</italic> CV experiment 1 for method RR-BLUP and <italic>j</italic> = validation population 2012 DS).</p><p>significant difference in the performance of the six statistical methods across the different experiments, i.e., where <italic>y</italic>
<sub><italic>i</italic></sub> (accuracy) = <italic>&#956;</italic> + <italic>x</italic>
<sub><italic>ij</italic></sub>
<italic>&#946;</italic>
<sub><italic>j</italic></sub> + <italic>&#949;</italic>
<sub><italic>ij</italic></sub>, and <italic>i</italic> is one RYT experiment for stat method <italic>j</italic> (e.g. <italic>x</italic>
<sub><italic>i</italic></sub> = CV experiment 1 and <italic>j</italic> = RR-BLUP).</p><p>significant difference in the performance of each experiment across statistical methods, after excluding the three worst-performing statistical methods (Bayesian LASSO, MLR, and pedigree only), i.e., where <italic>y</italic>
<sub><italic>i</italic></sub> (accuracy) = <italic>&#956;</italic> + <italic>x</italic>
<sub><italic>ij</italic></sub>
<italic>&#946;</italic>
<sub><italic>j</italic></sub> + <italic>&#949;</italic>
<sub><italic>ij</italic>,</sub> and <italic>i</italic> is one statistical method for RYT experiment <italic>j</italic> (e.g. <italic>x</italic>
<sub><italic>i</italic></sub> = RR-BLUP and j = CV experiment 1) (<xref ref-type="table" rid="pgen.1004982.t001">Table 1</xref>, <xref ref-type="supplementary-material" rid="pgen.1004982.s007">S2</xref>&#8211;<xref ref-type="supplementary-material" rid="pgen.1004982.s009">S4</xref> Tables).</p><p>
<bold>Distributed</bold>. To select subsets of SNPs that were evenly distributed across the genome, 11 bin parameters were selected: 25Kb (0.1 cM), 50 Kb (0.2 cM), 120 Kb (.5 cM), 240Kb (1 cM), 480 Kb (2 cM), 840 Kb (3.5 cM), 1200 Kb (5 cM), 1800 Kb (7.5 cM), 2400 Kb (10 cM), 3600 Kb (15 cM), 4800 Kb (20 cM). For each bin parameter, all SNPs in the 73,147 SNP set were placed into bins according to the bin parameter. To select subsets of SNPs for a given bin size, the SNPs in each bin were sorted first by minor allele frequency, largest to smallest, and then by call rate, largest to smallest. Ten selections of SNPs were made for each bin size&#8212;the first subset consisted of the top ranked SNP in each bin, i.e., the SNP with the highest MAF and call rate, the second subset consisted of the second ranked SNP in each bin, and so on for the top ten SNPs in each bin. If a bin had fewer than ten SNPs, then the top SNP in each bin was chosen for all ten selections.</p><p>Each subset was then used as the genotype matrix to perform five-fold cross-validation using the same folds as for the original RYT cross validation experiments. The RYT 2012 wet season and the RYT 2012 dry season served as the validation populations and RYT years 2009&#8211;2011, all seasons, served as the training population. The five marker-dependent statistical methods tested previously were used once more: RR-BLUP, RKHS, Random Forest, Bayesian LASSO, and MLR. Accuracy was calculated for each of the ten selections (for each bin parameter) as previously. A mean accuracy, standard deviation, and standard error for each bin parameter were also calculated by averaging the cross-validation results of the 10 selections for each bin parameter (<xref ref-type="supplementary-material" rid="pgen.1004982.s010">S5 Table</xref>).</p><p>The average accuracies with standard error as the error bars were plotted versus the number of SNPs in each subset (as determined by the bin size parameter) using JMP (Figs. <xref ref-type="fig" rid="pgen.1004982.g001">1</xref>, <xref ref-type="supplementary-material" rid="pgen.1004982.s004">S4</xref>). The results for full 73,147 SNP set were included on these plots as a reference, although these accuracies are not averages. ANOVA and pairwise students were used to test for significant difference in the performance of the five statistical methods across the different bin parameter sizes, and for significant differences in the performance of the various bin parameter sizes (and thus total SNP number) across the five statistical methods (<xref ref-type="supplementary-material" rid="pgen.1004982.s010">S5</xref>&#8211;<xref ref-type="supplementary-material" rid="pgen.1004982.s011">S6</xref> Tables).</p><p>
<bold>Random</bold>. Ten random selections of SNPs were chosen from the 73,147 SNP set for 15 subset sizes: 24, 48, 65, 83, 96, 109, 161, 212, 316, 448, 781, 1553, 3076, 7142, 13101 using a pseudo-random numbers generator. Subset sizes 83, 109, 161, 212, 316, 448, 781, 1553, 3076, 7142, and 13101 were chosen to match the number of SNPs in the distributed SNP subsets described above. The additional SNP subset sizes were included to improve resolution.</p><p>Cross validation experiments and analysis were performed for the random subsets as described above for the distributed subsets (<xref ref-type="fig" rid="pgen.1004982.g001">Fig. 1</xref>, <xref ref-type="supplementary-material" rid="pgen.1004982.s004">S4 Fig.</xref>, <xref ref-type="supplementary-material" rid="pgen.1004982.s011">S6 Table</xref>).</p>